{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115943cb-9ae0-4fee-8a30-7e652314c9da",
   "metadata": {},
   "source": [
    "# LLMs for Classification Workshops\n",
    "\n",
    "### Workshops\n",
    "- Amazon Bedrock [https://catalog.us-east-1.prod.workshops.aws/workshops/a4bdb007-5600-4368-81c5-ff5b4154f518/en-US]\n",
    "- Structured Prompting [https://github.com/stephenhibbert/instructor/tree/main/docs/tutorials]\n",
    "- Prompt Engineering [https://www.promptingguide.ai/]\n",
    "\n",
    "### Homework\n",
    "- Implement a predictor using the instructor AnthropicBedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc1160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232085b7-7191-4765-a09a-a7648acc14d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -qU datasets scikit-learn matplotlib\n",
    "! pip install -qU transformers torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770cbc3b-a9bd-49c4-ad92-136b71dfd1fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"fancyzhx/ag_news\")\n",
    "dataset = dataset.shuffle(seed=52)\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Take a sample of 100 examples from the train dataset\n",
    "train_sample = train_dataset.select(range(100))\n",
    "\n",
    "# Verify the sample size\n",
    "print(f\"Train sample size: {len(train_sample)}\")\n",
    "\n",
    "# Check the first few entries of the train sample\n",
    "print(train_sample[:3])\n",
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353c1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_predictions(true_labels, predictions):\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "label_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "labels = [0, 1, 2, 3]  # World (0), Sports (1), Business (2), Sci/Tech (3)\n",
    "\n",
    "# Create id2label and label2id dictionaries\n",
    "id2label = {i: label_names[i] for i in labels}\n",
    "label2id = {label_names[i]: i for i in labels}\n",
    "\n",
    "def id2label_func(id):\n",
    "    return id2label.get(id, \"Unknown\")\n",
    "\n",
    "def label2id_func(label):\n",
    "    return label2id.get(label, -1)\n",
    "\n",
    "def run_experiment(predict_func, evaluate_func, dataset_sample):\n",
    "    \n",
    "    # Make predictions for the test set\n",
    "    predictions = predict_func(dataset_sample)\n",
    "    \n",
    "    # Extract true labels from the test set\n",
    "    true_labels = dataset_sample['label']\n",
    "    \n",
    "    # Evaluate the predictions\n",
    "    evaluation_results = evaluate_func(true_labels, predictions)\n",
    "    \n",
    "    # Create a summary DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'True Label': true_labels,\n",
    "        'Prediction': predictions\n",
    "    })\n",
    "    \n",
    "    # Display the performance\n",
    "    print(f\"Experiment Results: {evaluation_results}\")\n",
    "    \n",
    "    return results, evaluation_results\n",
    "\n",
    "def plot_results(results):\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(results['True Label'], results['Prediction'], labels=[0, 1, 2, 3])\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['World', 'Sports', 'Business', 'Sci/Tech'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the distribution of predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    results['Prediction'].value_counts().sort_index().plot(kind='bar', color='skyblue')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Random Predictions')\n",
    "    plt.xticks(ticks=[0, 1, 2, 3], labels=['World', 'Sports', 'Business', 'Sci/Tech'], rotation=0)\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eac573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_predictor(test_data):\n",
    "    return [random.choice(labels) for _ in range(len(test_data))]\n",
    "\n",
    "# Run the experiment with the random predictor\n",
    "results, evaluation_results = run_experiment(random_predictor, evaluate_predictions, train_sample)\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a44e9",
   "metadata": {},
   "source": [
    "### Now we can try some different predictor function.... how about always predicting the same thing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7a212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def constant_predictor(test_data):\n",
    "    predicted_labels = []\n",
    "    for _ in range(len(test_data)):\n",
    "        predicted_labels.append(0) # How about if we just always predict 0?\n",
    "    return predicted_labels\n",
    "\n",
    "results, evaluation_results = run_experiment(constant_predictor, evaluate_predictions, train_sample)\n",
    "plot_results(results)\n",
    "# Pretty bad, but maybe slightly better than random ðŸ™ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c22141",
   "metadata": {
    "tags": []
   },
   "source": [
    "Okay, let's try to be a bit smarter - I know you're very comfortable deploying supervised learning algos but I want you to take a purely transfer learning approach for now. \n",
    "We will apply some pretrained large models and experiment with prompt engineering before visiting any training from scratch or fine-tuning.\n",
    "\n",
    " Let's grab a large(ish) model from Hugging Face and see how it performs on the task of zero shot text classification\n",
    " https://huggingface.co/tasks/zero-shot-classification\n",
    "\n",
    " Have a read about the BART model architecture here: https://arxiv.org/pdf/1910.13461\n",
    " \n",
    "*We present BART, a denoising autoencoder for pretraining sequence-to-sequence models.\n",
    "BART is trained by (1) corrupting text with an\n",
    "arbitrary noising function, and (2) learning a\n",
    "model to reconstruct the original text. It uses\n",
    "a standard Tranformer-based neural machine\n",
    "translation architecture which, despite its simplicity, can be seen as generalizing BERT (due\n",
    "to the bidirectional encoder), GPT (with the\n",
    "left-to-right decoder), and many other more recent pretraining schemes\n",
    "We'll start by copying the example in the link above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7de27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline\n",
    "\n",
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "output = pipe(\"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"]\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28435f0d-e9e5-40e7-b1bf-20e01c23f32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -qU tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b7795-0a6f-4de4-998b-f9428fcd9a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's speed things up - use the GPU and the built in map function\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Assuming pipe is a transformers pipeline\n",
    "pipe = pipeline('zero-shot-classification', model='facebook/bart-large-mnli', device=device)\n",
    "\n",
    "def bart_large_mnli_predictor(test_data):\n",
    "    predicted_labels = []\n",
    "    for datum in tqdm(test_data, desc=\"Processing\"):\n",
    "        output = pipe(datum['text'], candidate_labels=['World', 'Sports', 'Business', 'Sci/Tech'])\n",
    "        max_label = output['labels'][output['scores'].index(max(output['scores']))]\n",
    "        predicted_labels.append(label2id_func(max_label))\n",
    "    return predicted_labels\n",
    "\n",
    "# Ensure the lambda function matches the expected input of run_experiment\n",
    "results, evaluation_results = run_experiment(bart_large_mnli_predictor, evaluate_predictions, train_sample)\n",
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585c991-f085-447e-925f-6f375d5c287e",
   "metadata": {},
   "source": [
    "### Use Anthropic Claude 3 on Bedrock\n",
    "Apply the examples from the instructor structured prompting notebooks to this. Implement the `claude_haiku_predictor` function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b02612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_haiku_predictor(test_data):\n",
    "    raise Exception(\"Not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018890e4-996d-40e8-a04c-822a0fe92d47",
   "metadata": {},
   "source": [
    "### (Optional) What about a capable open source LLM? See if you can adapt this to work with Llama3.1\n",
    "\n",
    "The following uses a small Llama 3.1 model, note you'll need to accept the T&C's and wait a few mins to be able to use the model as it's gated on the HF hub.\n",
    "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
